{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9023b258",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importação de bibliotecas\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import openslide #para carregar os ficheiros .svs\n",
    "import random\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm  # barra de progresso\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, accuracy_score, auc as calc_auc, precision_recall_curve\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras.applications import ResNet50, resnet50, EfficientNetB0\n",
    "from tensorflow.keras import layers, models, callbacks, optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout,  GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import (EarlyStopping, ReduceLROnPlateau)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb6c1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#carregar e visualizar as imagens \n",
    "\n",
    "# Caminho para a pasta onde estão os ficheiros .svs\n",
    "image_folder = \"/Volumes/TOSHIBA EXT/Trabalho final/SLN-Breast\"\n",
    "image_files = os.listdir(image_folder)\n",
    "\n",
    "# Aumentar o limite de pixels para evitar o erro DecompressionBombError\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "\n",
    "#Carregar e mostrar uma imagem de exemplo\n",
    "img_path = os.path.join(image_folder, image_files[0])\n",
    "img = Image.open(img_path)\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.title(\"Exemplo de imagem citológica\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccb9557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dados suplementares\n",
    "df = pd.read_csv(\"/Volumes/TOSHIBA EXT/Trabalho final/SLN-Breast/target.csv\")\n",
    "\n",
    "# Visualizar as primeiras linhas\n",
    "print(df.head())\n",
    "\n",
    "# Verificar distribuição das classes\n",
    "print(df['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32be0f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combinar as imagens com os dados do CSV\n",
    "# Exemplo: carregar uma imagem com base no nome no CSV\n",
    "sample = df.iloc[0]\n",
    "img_path = os.path.join(image_folder, sample['slide'])\n",
    "img = Image.open(img_path)\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.title(f\"Diagnóstico: {sample['target']}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79867f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---  Pré-processar cada imagem ---\n",
    "\n",
    "patch_size = 224\n",
    "n_patches_por_classe = 500 # número de patches por classe para ajudar a equilibrar o dataset\n",
    "min_tissue_ratio = 0.6  # número de patches por imagem\n",
    "data = []\n",
    "counts_per_class = defaultdict(int)\n",
    "\n",
    "# Agrupar imagens por classe para facilitar a extração balanceada\n",
    "df_grouped = df.groupby('target')\n",
    "\n",
    "\n",
    "# Vai tentar extrair patches para cada classe até atingir n_patches_por_classe\n",
    "for classe, grupo in df_grouped:\n",
    "    print(f\"[INFO] A extrair patches da classe {classe}...\")\n",
    "    imagens_classe = grupo['slide'].tolist()\n",
    "    random.shuffle(imagens_classe)  # embaralha a ordem das imagens\n",
    "    \n",
    "    idx_imagem = 0\n",
    "    while counts_per_class[classe] < n_patches_por_classe:\n",
    "        if idx_imagem >= len(imagens_classe):\n",
    "            print(f\"[AVISO] Imagens acabaram antes de atingir {n_patches_por_classe} patches para a classe {classe}\")\n",
    "            break\n",
    "        \n",
    "        file_path = os.path.join(image_folder, imagens_classe[idx_imagem])\n",
    "        idx_imagem += 1\n",
    "        \n",
    "        try:\n",
    "            slide = openslide.OpenSlide(file_path)\n",
    "            slide_w, slide_h = slide.dimensions\n",
    "            \n",
    "            patches_collected = 0\n",
    "            max_attempts = 100  # limite para evitar loops infinitos em imagens sem patches válidos\n",
    "            attempts = 0\n",
    "            \n",
    "            while patches_collected < n_patches_por_classe // len(imagens_classe) and attempts < max_attempts:\n",
    "                x = random.randint(0, slide_w - patch_size)\n",
    "                y = random.randint(0, slide_h - patch_size)\n",
    "                \n",
    "                patch = slide.read_region((x, y), 0, (patch_size, patch_size)).convert(\"RGB\")\n",
    "                patch_array = np.array(patch) / 255.0\n",
    "                \n",
    "                tissue_ratio = (patch_array.mean(axis=2) < 0.9).mean()\n",
    "                if tissue_ratio >= min_tissue_ratio:\n",
    "                    data.append((patch_array, classe))\n",
    "                    counts_per_class[classe] += 1\n",
    "                    patches_collected += 1\n",
    "                attempts += 1\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"[ERRO] {file_path}: {e}\")\n",
    "\n",
    "print(\"[INFO] Distribuição final de patches por classe:\")\n",
    "for classe, count in counts_per_class.items():\n",
    "    print(f\"Classe {classe}: {count} patches\")\n",
    "\n",
    "# Converter para arrays numpy\n",
    "X = np.array([img for img, _ in data])\n",
    "y = np.array([label for _, label in data])\n",
    "print(f\"Total patches: {len(X)} | Shape: {X.shape} | Class distribution: {np.bincount(y)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e313d054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Dividir e guardar patches em diretórios ---\n",
    "base_dir = \"/Volumes/TOSHIBA EXT/Trabalho final/PKG - SLN-Breast\"\n",
    "train_dir, test_dir = os.path.join(base_dir, \"train\"), os.path.join(base_dir, \"test\")\n",
    "for d in [train_dir, test_dir]:\n",
    "    for c in [\"0\", \"1\"]:\n",
    "        os.makedirs(os.path.join(d, c), exist_ok=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "def save_images(X, y, path_prefix):\n",
    "    for i, (img_array, label) in enumerate(zip(X, y)):\n",
    "        img = Image.fromarray((img_array * 255).astype(np.uint8))\n",
    "        img.save(os.path.join(path_prefix, str(label), f\"{path_prefix.split('/')[-1]}_{i}.png\"))\n",
    "\n",
    "save_images(X_train, y_train, train_dir)\n",
    "save_images(X_test, y_test, test_dir)\n",
    "\n",
    "# --- Geradores de dados ---\n",
    "img_size = (224, 224)\n",
    "batch_size = 16\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)  # Caso tenhas guardado sem normalizar\n",
    "\n",
    "train_ds = datagen.flow_from_directory(train_dir, target_size=img_size, batch_size=batch_size, class_mode='binary')\n",
    "test_ds = datagen.flow_from_directory(test_dir, target_size=img_size, batch_size=batch_size, class_mode='binary', shuffle=False)\n",
    "\n",
    "# --- Modelagem com EfficientNetB0 ---\n",
    "base_model = EfficientNetB0(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "base_model.trainable = False\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(base_model.output)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "x = layers.Dropout(0.4)(x)\n",
    "out = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = models.Model(inputs=base_model.input, outputs=out)\n",
    "model.compile(optimizer=optimizers.Adam(1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# --- Class weights ---\n",
    "y_train_labels = train_ds.classes\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train_labels), y=y_train_labels)\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "print(\"Class weights:\", class_weights)\n",
    "\n",
    "# --- Treinar modelo ---\n",
    "cb = [\n",
    "    callbacks.EarlyStopping(patience=5, restore_best_weights=True),\n",
    "    callbacks.ReduceLROnPlateau(patience=3, factor=0.2),\n",
    "    callbacks.ModelCheckpoint(\"best_model.h5\", save_best_only=True)\n",
    "]\n",
    "\n",
    "history = model.fit(train_ds, validation_data=test_ds, epochs=30, class_weight=class_weights, callbacks=cb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5b5c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Avaliação geral do modelo\n",
    "loss, acc = model.evaluate(test_ds)\n",
    "print(f\"Accuracy: {acc:.3f}\")\n",
    "\n",
    "# Extrair rótulos reais e previsões\n",
    "y_true = test_ds.labels\n",
    "y_probs = model.predict(test_ds).ravel()\n",
    "\n",
    "\n",
    "# AUC-ROC\n",
    "auc_score = roc_auc_score(y_true, y_probs)\n",
    "print(f\"AUC-ROC: {auc_score:.3f}\")\n",
    "\n",
    "# Curva ROC\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_probs)\n",
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "print(f\"Threshold ótimo: {optimal_threshold:.3f}\")\n",
    "\n",
    "# Previsões com threshold otimizado\n",
    "y_pred_opt = (y_probs > optimal_threshold).astype(int)\n",
    "\n",
    "# Matriz de confusão\n",
    "cm = confusion_matrix(y_true, y_pred_opt)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel(\"Previsto\")\n",
    "plt.ylabel(\"Real\")\n",
    "plt.title(\"Matriz de Confusão (Threshold Otimizado)\")\n",
    "plt.show()\n",
    "\n",
    "# Relatório de classificação\n",
    "class_names = ['0', '1']\n",
    "print(classification_report(y_true, y_pred_opt, target_names=class_names))\n",
    "\n",
    "# Curva ROC\n",
    "plt.plot(fpr, tpr, label=f'AUC = {auc_score:.3f}')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Curva ROC\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
